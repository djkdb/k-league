import torch
from torch.utils.data import DataLoader, random_split
from src.config import Config
from src.dataset import SoccerEventDataset
from src.model import ImprovedSpatialTemporalTransformer
from src.trainer import train_model
from src.feature_engineering import feature_engineering
from src.utils import seed_everything
import pandas as pd
import os

def main():
    # 0. ì‹œë“œ ê³ ì •
    seed_everything(Config.SEED)
    print(f"ğŸš€ í”„ë¡œì íŠ¸ ì‹œì‘ | Device: {Config.DEVICE}")
    
    # ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(os.path.dirname(Config.MODEL_SAVE_PATH), exist_ok=True)
    
    # 1. ë°ì´í„° ë¡œë“œ
    try:
        print(f"ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘: {Config.TRAIN_PATH}")
        df = pd.read_csv(Config.TRAIN_PATH)
        print(f"   ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}")
    except FileNotFoundError:
        print(f"âŒ ì—ëŸ¬: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. {Config.TRAIN_PATH}")
        return
    
    # 2. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ìˆ˜í–‰
    print("ğŸ”§ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ìˆ˜í–‰ ì¤‘...")
    processed_df, encoders = feature_engineering(df)
    print(f"   ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: {processed_df.shape}")
    
    # 3. ë°ì´í„°ì…‹ ìƒì„±
    print(f"ğŸ“Š ë°ì´í„°ì…‹ ìƒì„± ì¤‘ (SEQ_LEN={Config.SEQ_LEN})...")
    full_dataset = SoccerEventDataset(
        processed_df, 
        seq_len=Config.SEQ_LEN, 
        is_train=True
    )
    
    # Train / Validation Split (8:2)
    total_size = len(full_dataset)
    train_size = int(0.8 * total_size)
    val_size = total_size - train_size
    
    train_dataset, val_dataset = random_split(
        full_dataset, 
        [train_size, val_size],
        generator=torch.Generator().manual_seed(Config.SEED)
    )
    
    print(f"   âœ… Train: {len(train_dataset)} | Val: {len(val_dataset)}")
    
    # 4. DataLoader ìƒì„±
    train_loader = DataLoader(
        train_dataset, 
        batch_size=Config.BATCH_SIZE, 
        shuffle=True, 
        drop_last=True,
        num_workers=0  # Windows í˜¸í™˜ì„±
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=Config.BATCH_SIZE, 
        shuffle=False,
        num_workers=0
    )
    
    # 5. ëª¨ë¸ ì…ë ¥ í¬ê¸° ê³„ì‚°
    print("ğŸ” ëª¨ë¸ ì…ë ¥ í¬ê¸° ê³„ì‚° ì¤‘...")
    sample_x_cont, sample_x_cat, _ = full_dataset[0]
    num_cont_features = sample_x_cont.shape[1]
    
    # ë²”ì£¼í˜• ë³€ìˆ˜ ì°¨ì›
    cat_dims = []
    target_cat_cols = ['type_name', 'team_id']
    
    for col in target_cat_cols:
        if col in encoders:
            cat_dims.append(len(encoders[col].classes_))
        else:
            print(f"âš ï¸ ê²½ê³ : {col}ì— ëŒ€í•œ ì¸ì½”ë” ì—†ìŒ. ê¸°ë³¸ê°’ 100 ì‚¬ìš©")
            cat_dims.append(100)
    
    print(f"   ì—°ì†í˜• í”¼ì²˜: {num_cont_features}ê°œ")
    print(f"   ë²”ì£¼í˜• ì°¨ì›: {cat_dims}")
    
    # 6. ëª¨ë¸ ìƒì„±
    print("ğŸ—ï¸ ëª¨ë¸ ìƒì„± ì¤‘...")
    model = ImprovedSpatialTemporalTransformer(
        num_cont_features=num_cont_features,
        cat_dims=cat_dims,
        embed_dim=Config.EMBED_DIM,
        num_layers=Config.NUM_LAYERS,
        seq_len=Config.SEQ_LEN,
        nhead=Config.NHEAD
    ).to(Config.DEVICE)
    
    # ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ì¶œë ¥
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"   ì´ íŒŒë¼ë¯¸í„°: {total_params:,}")
    print(f"   í•™ìŠµ ê°€ëŠ¥: {trainable_params:,}")
    
    # 7. í•™ìŠµ ì‹œì‘
    print("\n" + "=" * 60)
    print("ğŸ“ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    print("=" * 60)
    
    train_model(model, train_loader, val_loader, Config)
    
    print("\nâœ… ëª¨ë“  ê³¼ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()