"""
ì—¬ëŸ¬ ì‹œë“œë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ì—¬ ì•™ìƒë¸”ìš© ëª¨ë¸ ìƒì„±
"""
import torch
from torch.utils.data import DataLoader, random_split
from src.config import Config
from src.dataset import SoccerEventDataset
from src.model import ImprovedSpatialTemporalTransformer
from src.trainer import train_model
from src.feature_engineering import feature_engineering
from src.utils import seed_everything
import pandas as pd
import os

def train_with_seed(seed, model_save_path):
    """íŠ¹ì • ì‹œë“œë¡œ ëª¨ë¸ í•™ìŠµ"""
    print(f"\n{'='*60}")
    print(f"ğŸŒ± SEED {seed}ë¡œ í•™ìŠµ ì‹œì‘")
    print(f"{'='*60}\n")
    
    # ì‹œë“œ ì„¤ì •
    seed_everything(seed)
    
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(Config.TRAIN_PATH)
    processed_df, encoders = feature_engineering(df)
    
    # ë°ì´í„°ì…‹ ìƒì„±
    full_dataset = SoccerEventDataset(
        processed_df, 
        seq_len=Config.SEQ_LEN, 
        is_train=True
    )
    
    # Train/Val Split
    total_size = len(full_dataset)
    train_size = int(0.8 * total_size)
    val_size = total_size - train_size
    
    train_dataset, val_dataset = random_split(
        full_dataset, 
        [train_size, val_size],
        generator=torch.Generator().manual_seed(seed)
    )
    
    # DataLoader
    train_loader = DataLoader(
        train_dataset, 
        batch_size=Config.BATCH_SIZE, 
        shuffle=True, 
        drop_last=True,
        num_workers=0
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=Config.BATCH_SIZE, 
        shuffle=False,
        num_workers=0
    )
    
    # ëª¨ë¸ ìƒì„±
    sample_x_cont, sample_x_cat, _ = full_dataset[0]
    num_cont_features = sample_x_cont.shape[1]
    
    cat_dims = []
    target_cat_cols = ['type_name', 'team_id']
    for col in target_cat_cols:
        if col in encoders:
            cat_dims.append(len(encoders[col].classes_))
        else:
            cat_dims.append(100)
    
    model = ImprovedSpatialTemporalTransformer(
        num_cont_features=num_cont_features,
        cat_dims=cat_dims,
        embed_dim=Config.EMBED_DIM,
        num_layers=Config.NUM_LAYERS,
        seq_len=Config.SEQ_LEN,
        nhead=Config.NHEAD
    ).to(Config.DEVICE)
    
    # í•™ìŠµ (ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì„ì‹œ ë³€ê²½)
    original_path = Config.MODEL_SAVE_PATH
    Config.MODEL_SAVE_PATH = model_save_path
    
    train_model(model, train_loader, val_loader, Config)
    
    Config.MODEL_SAVE_PATH = original_path
    
    print(f"\nâœ… SEED {seed} ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}\n")

def main():
    """ì—¬ëŸ¬ ì‹œë“œë¡œ ëª¨ë¸ í•™ìŠµ"""
    
    # ì•™ìƒë¸”í•  ì‹œë“œ ëª©ë¡ (5ê°œ ì •ë„ ì¶”ì²œ)
    seeds = [42, 123, 456, 789, 2024]
    
    print("ğŸ¯ ë‹¤ì¤‘ ì‹œë“œ í•™ìŠµ ì‹œì‘")
    print(f"ì´ {len(seeds)}ê°œ ëª¨ë¸ í•™ìŠµ ì˜ˆì •")
    print(f"ì‹œë“œ ëª©ë¡: {seeds}")
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("./saved_models", exist_ok=True)
    
    # ê° ì‹œë“œë¡œ í•™ìŠµ
    for i, seed in enumerate(seeds):
        model_path = f"./saved_models/best_model_seed{seed}.pth"
        
        try:
            train_with_seed(seed, model_path)
        except Exception as e:
            print(f"âŒ SEED {seed} í•™ìŠµ ì‹¤íŒ¨: {e}")
            continue
        
        print(f"\nì§„í–‰ë¥ : {i+1}/{len(seeds)} ì™„ë£Œ\n")
    
    print("\n" + "="*60)
    print("ğŸ‰ ëª¨ë“  ì‹œë“œ í•™ìŠµ ì™„ë£Œ!")
    print("="*60)
    print("\nì•™ìƒë¸” ì¶”ë¡ ì„ ìœ„í•´ inference_ensemble.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
    print("python inference_ensemble.py")

if __name__ == "__main__":
    main()